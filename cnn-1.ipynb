{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d048f23f",
   "metadata": {
    "id": "FE7KNzPPVrVV"
   },
   "source": [
    "# Clasificación de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7de38",
   "metadata": {
    "id": "gN7G9GFmVrVY"
   },
   "source": [
    "Este tutorial muestra cómo clasificar imágenes de flores utilizando un modelo `tf.keras.Sequential` y cargar datos utilizando `tf.keras.utils.image_dataset_from_directory`. Demuestra los siguientes conceptos:\n",
    "\n",
    "- Carga eficaz de un conjunto de datos del disco.\n",
    "- La identificación del sobreajuste y la aplicación de técnicas para mitigarlo, incluidos el aumento de datos y abandonarlos.\n",
    "\n",
    "Este tutorial sigue un flujo de trabajo básico de aprendizaje automático:\n",
    "\n",
    "1. Examinar y comprender los datos\n",
    "2. Construirá una canalización de entrada\n",
    "3. Construir el modelo\n",
    "4. Entrene el modelo\n",
    "5. Pruebe el modelo\n",
    "6. Mejore el modelo y repita el proceso\n",
    "\n",
    "Además, el bloc de notas demuestra cómo convertir un [modelo guardado](../../../guide/saved_model.ipynb) en un [modelo de TensorFlow Lite](https://www.tensorflow.org/lite/) para el aprendizaje automático en dispositivos móviles, embebidos y de IoT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954a077b",
   "metadata": {
    "id": "zF9uvbXNVrVY"
   },
   "source": [
    "## Preparación\n",
    "\n",
    "Importe TensorFlow y otras bibliotecas necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40e542",
   "metadata": {
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7284ad",
   "metadata": {
    "id": "UZZI6lNkVrVm"
   },
   "source": [
    "## Descargar y explorar el conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb2f50c",
   "metadata": {
    "id": "DPHx8-t-VrVo"
   },
   "source": [
    "Este tutorial utiliza un conjunto de datos de unas 3,700 fotos de flores. El conjunto de datos contiene cinco subdirectorios, uno por clase:\n",
    "\n",
    "```\n",
    "flower_photo/\n",
    "  daisy/\n",
    "  dandelion/\n",
    "  roses/\n",
    "  sunflowers/\n",
    "  tulips/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f5957",
   "metadata": {
    "id": "57CcilYSG0zv",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, extract=True)\n",
    "data_dir = pathlib.Path(data_dir).parent / \"flower_photos\"  # Ajustamos la ruta extraída\n",
    "\n",
    "# Contar imágenes correctamente\n",
    "image_count = len(list(data_dir.glob('*/*/*.jpg')))\n",
    "print(f\"Total de imágenes: {image_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d1d19",
   "metadata": {
    "id": "VpmywIlsVrVx"
   },
   "source": [
    "Después de la descarga, ya debería disponer de una copia del conjunto de datos. Hay 3,670 imágenes en total:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e1535b",
   "metadata": {
    "id": "PVmwkOSdHZ5A"
   },
   "source": [
    "Estas son algunas rosas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc82a92",
   "metadata": {
    "id": "N1loMlbYHeiJ"
   },
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('flower_photos/roses/*'))\n",
    "PIL.Image.open(str(roses[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39d26b",
   "metadata": {
    "id": "RQbZBOTLHiUP"
   },
   "outputs": [],
   "source": [
    "PIL.Image.open(str(roses[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3c5b5b",
   "metadata": {
    "id": "DGEqiBbRHnyI"
   },
   "source": [
    "Y algunos tulipanes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04e635",
   "metadata": {
    "id": "HyQkfPGdHilw"
   },
   "outputs": [],
   "source": [
    "tulips = list(data_dir.glob('flower_photos/tulips/*'))\n",
    "PIL.Image.open(str(tulips[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9a0f1",
   "metadata": {
    "id": "wtlhWJPAHivf"
   },
   "outputs": [],
   "source": [
    "PIL.Image.open(str(tulips[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c98f55",
   "metadata": {
    "id": "gIjgz7_JIo_m"
   },
   "source": [
    "## Cargar datos con una utilidad de Keras\n",
    "\n",
    "A continuación, cargue estas imágenes desde el disco utilizando la útil utilidad `tf.keras.utils.image_dataset_from_directory`. Esto nos permitirá pasar de un directorio de imágenes en disco a un `tf.data.Dataset` con sólo un par de líneas de código. Si lo desea, también puede escribir su propio código para cargar datos desde cero visitando el tutorial [Cargar y preprocesar imágenes](../load_data/images.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b527f",
   "metadata": {
    "id": "xyDNn9MbIzfT"
   },
   "source": [
    "### Crear un conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b2b5ae",
   "metadata": {
    "id": "anqiK_AGI086"
   },
   "source": [
    "Defina algunos parámetros para el cargador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafbd63",
   "metadata": {
    "id": "H74l2DoDI2XD"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06867818",
   "metadata": {
    "id": "pFBhRrrEI49z"
   },
   "source": [
    "Es una práctica recomendada utilizar una división de validación cuando desarrolle su modelo. Utilice el 80% de las imágenes para el entrenamiento y el 20% para la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f375ed",
   "metadata": {
    "id": "fIR0kRZiI_AT"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa6a18",
   "metadata": {
    "id": "iscU3UoVJBXj"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f0b53",
   "metadata": {
    "id": "WLQULyAvJC3X"
   },
   "source": [
    "Puede encontrar los nombres de las clases en el atributo `class_names` de estos conjuntos de datos. Éstos corresponden a los nombres de los directorios por orden alfabético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e1ea4",
   "metadata": {
    "id": "ZHAxkHX5JD3k"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d1647c",
   "metadata": {
    "id": "_uoVvxSLJW9m"
   },
   "source": [
    "## Visualizar los datos\n",
    "\n",
    "Estas son las nueve primeras imágenes del conjunto de datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e16f8",
   "metadata": {
    "id": "wBmEA9c0JYes"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c02784",
   "metadata": {
    "id": "5M6BXtXFJdW0"
   },
   "source": [
    "Pasará estos conjuntos de datos al método Keras `Model.fit` para el entrenamiento más adelante en este tutorial. Si lo desea, también puede iterar manualmente el conjunto de datos y recuperar lotes de imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea6921",
   "metadata": {
    "id": "2-MfMoenJi8s"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a7c4d",
   "metadata": {
    "id": "Wj4FrKxxJkoW"
   },
   "source": [
    "El lote de imagen `image_batch` es un tensor de la forma `(32, 180, 180, 3)`. Esto es un lote de 32 imágenes de forma `180x180x3` (la última dimensión hace referencia a los canales de color RGB). El lote `label_batch` es un tensor de la forma `(32,)`, estas son etiquetas que concuerdan con las 32 imágenes.\n",
    "\n",
    "Puede llamar a `.numpy()` sobre los tensores `image_batch` y `labels_batch` para convertirlos en un `numpy.ndarray`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ff3a8",
   "metadata": {
    "id": "4Dr0at41KcAU"
   },
   "source": [
    "## Configuración del conjunto de datos para rendimiento\n",
    "\n",
    "Asegúrese de utilizar la preextracción de datos en búfer, para poder ceder los datos desde el disco sin que la E/S se bloquee. Estos son dos métodos importantes que debe utilizar al cargar datos:\n",
    "\n",
    "- `Dataset.cache` conserva los datos en la memoria después de que se carga desde el disco durante la primera época. Así se garantiza que el conjunto de datos no se transforme en un cuello de botella mientras entrena su modelo. Si su conjunto de datos es muy grande para guardar en la memoria, también puede usar este método para crear un caché en disco de alto rendimiento.\n",
    "- `Dataset.prefetch` superpone el preprocesamiento de los datos y la ejecución del modelo durante el entrenamiento.\n",
    "\n",
    "Quienes quieran aprender más sobre ambos modelos y también sobre cómo copiar datos en caché en disco, pueden leer la sección *Preextracción* de la guía [Mejor rendimiento con la API tf.data](../../guide/data_performance.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcff469",
   "metadata": {
    "id": "nOjJSm7DKoZA"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d52e0",
   "metadata": {
    "id": "8GUnmPF4JvEf"
   },
   "source": [
    "## Estandarizar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba8549",
   "metadata": {
    "id": "e56VXHMWJxYT"
   },
   "source": [
    "Los valores del canal RGB están dentro del rango `[0, 255]`, lo cual no es ideal para una red neuronal. En general, debería buscar que los valores de su entrada sean bajos.\n",
    "\n",
    "Aquí, estandarizará los valores para que estén dentro del rango `[0, 1]` mediante el uso de `tf.keras.layers.Rescaling`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd9219",
   "metadata": {
    "id": "PEYxo2CTJvY9"
   },
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445a745",
   "metadata": {
    "id": "Bl4RmanbJ4g0"
   },
   "source": [
    "Esta capa se puede usar de dos formas. Se puede aplicar en el conjunto de datos llamando `Dataset.map`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0069934",
   "metadata": {
    "id": "X9o9ESaJJ502"
   },
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a672c",
   "metadata": {
    "id": "XWEOmRSBJ9J8"
   },
   "source": [
    "O bien, puede incluir la capa dentro de la definición de su modelo, lo que puede simplificar la implementación. Utilice aquí el segundo enfoque."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a5546",
   "metadata": {
    "id": "XsRk1xCwKZR4"
   },
   "source": [
    "Nota: Previamente, usaste el argumento `image_size` de `tf.keras.utils.image_dataset_from_directory` para ajustar el tamaño de las imágenes. Si también quiere incluir la lógica del ajuste en su modelo, puede usar la capa `tf.keras.layers.Resizing`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c62e9",
   "metadata": {
    "id": "WcUTyDOPKucd"
   },
   "source": [
    "## Un modelo básico de Keras\n",
    "\n",
    "### Crear el modelo\n",
    "\n",
    "El modelo [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) de Keras consta de tres bloques de convolución (`tf.keras.layers.Conv2D`) con una capa de agrupamiento máximo (`tf.keras.layers.MaxPooling2D`) en cada uno de ellos. Hay una capa totalmente conectada (`tf.keras.layers.Dense`) con 128 unidades en la parte superior que se activa mediante una función de activación ReLU (`'relu'`). Este modelo no se ajustó para obtener una gran precisión; el objetivo de este tutorial es mostrar un enfoque estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a423c",
   "metadata": {
    "id": "QR6argA1K074"
   },
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923fa1a0",
   "metadata": {
    "id": "EaKFzz72Lqpg"
   },
   "source": [
    "### Compilar el modelo\n",
    "\n",
    "Para este tutorial, elija el optimizador `tf.keras.optimizers.Adam` y la función de pérdida `tf.keras.losses.SparseCategoricalCrossentropy`. Para ver la precisión de entrenamiento y validación de cada época de entrenamiento, pase el argumento `metrics` a `Model.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953ad62",
   "metadata": {
    "id": "jloGNS1MLx3A"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca75de",
   "metadata": {
    "id": "aMJ4DnuJL55A"
   },
   "source": [
    "### Resumen del modelo\n",
    "\n",
    "Visualice todas las capas de la red utilizando el método Keras `Model.summary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab233a91",
   "metadata": {
    "id": "llLYH-BXL7Xe"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be50a2ec",
   "metadata": {
    "id": "NiYHcbvaL9H-"
   },
   "source": [
    "### Entrene el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8dfb1",
   "metadata": {
    "id": "j30F69T4sIVN"
   },
   "source": [
    "Entrene el modelo durante 10 épocas con el método Keras `Model.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709cf3dd",
   "metadata": {
    "id": "5fWToCqYMErH"
   },
   "outputs": [],
   "source": [
    "epochs=1\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46d573",
   "metadata": {
    "id": "SyFKdQpXMJT4"
   },
   "source": [
    "## Visualice los resultados del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345f85c",
   "metadata": {
    "id": "dFvOvmAmMK9w"
   },
   "source": [
    "Cree gráficos de la pérdida y la precisión en los conjuntos de entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a26497",
   "metadata": {
    "id": "jWnopEChMMCn"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a379dbf",
   "metadata": {
    "id": "hO_jT7HwMrEn"
   },
   "source": [
    "Las representaciones gráficas muestran que la precisión de entrenamiento y la de validación están alejadas por grandes márgenes, y que el modelo sólo ha logrado una precisión en torno al 60% en el conjunto de validación.\n",
    "\n",
    "Las siguientes secciones del tutorial muestran cómo inspeccionar lo que salió mal e intentar aumentar el rendimiento general del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec4894",
   "metadata": {
    "id": "hqtyGodAMvNV"
   },
   "source": [
    "## Sobreajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c026e0f7",
   "metadata": {
    "id": "ixsz9XFfMxcu"
   },
   "source": [
    "En las representaciones gráficas anteriores, la precisión de entrenamiento aumenta linealmente con el tiempo, mientras que la precisión de validación se estanca en torno al 60% en el proceso de entrenamiento. Además, la diferencia de precisión entre la precisión de entrenamiento y la de validación es notable, un signo de [sobreajuste](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit).\n",
    "\n",
    "Cuando hay un número reducido de ejemplos de entrenamiento, el modelo aprende a veces de los ruidos o de los detalles no deseados de los ejemplos de entrenamiento, hasta el punto de repercutir negativamente en el rendimiento del modelo con los nuevos ejemplos. Este fenómeno se conoce como sobreajuste. Significa que el modelo tendrá dificultades para generalizar en un nuevo conjunto de datos.\n",
    "\n",
    "Hay múltiples formas de combatir el sobreajuste en el proceso de entrenamiento. En este tutorial, utilizará el *aumento de datos* y agregará *abandonar* a su modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ea258",
   "metadata": {
    "id": "BDMfYqwmM1C-"
   },
   "source": [
    "## Aumento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23480c17",
   "metadata": {
    "id": "GxYwix81M2YO"
   },
   "source": [
    "El sobreajuste suele producirse cuando hay un número reducido de ejemplos en el entrenamiento. [El aumento de datos](./data_augmentation.ipynb) adopta el enfoque consistente en generar datos de entrenamiento adicionales a partir de los ejemplos existentes, al aumentarlos mediante transformaciones aleatorias que producen imágenes de aspecto realista. Esto ayuda a exponer el modelo a más aspectos de los datos y a generalizar mejor.\n",
    "\n",
    "Implementará el aumento de datos utilizando las siguientes capas de preprocesamiento de Keras: `tf.keras.layers.RandomFlip`, `tf.keras.layers.RandomRotation`, y `tf.keras.layers.RandomZoom`. Estas pueden incluirse dentro de su modelo como otras capas, y ejecutarse en la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06a398",
   "metadata": {
    "id": "9J80BAbIMs21"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d8ada",
   "metadata": {
    "id": "PN4k1dK3S6eV"
   },
   "source": [
    "Visualice algunos ejemplos aumentados aplicando varias veces el aumento de datos a la misma imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e88021",
   "metadata": {
    "id": "7Z90k539S838"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08162ba",
   "metadata": {
    "id": "tsjXCBLYYNs5"
   },
   "source": [
    "En el siguiente paso agregará el aumento de datos a su modelo antes del entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad646793",
   "metadata": {
    "id": "ZeD3bXepYKXs"
   },
   "source": [
    "## Abandonar\n",
    "\n",
    "Otra técnica para reducir el sobreajuste es introducir [abandonar](https://developers.google.com/machine-learning/glossary#dropout_regularization){:.external} regularización a la red.\n",
    "\n",
    "Cuando se aplica abandonar a una capa, se elimina aleatoriamente (poniendo la activación a cero) un número de unidades de salida de la capa durante el proceso de entrenamiento. Abandonar toma un número fraccionario como valor de entrada, en la forma como 0.1, 0.2, 0.4, etc. Esto significa descartar aleatoriamente el 10%, el 20% o el 40% de las unidades de salida de la capa aplicada.\n",
    "\n",
    "Cree una nueva red neuronal con `tf.keras.layers.Dropout` antes de entrenarla utilizando las imágenes aumentadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ebbd0e",
   "metadata": {
    "id": "2Zeg8zsqXCsm"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes, name=\"outputs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab0555",
   "metadata": {
    "id": "L4nEcuqgZLbi"
   },
   "source": [
    "## Compile y entrene el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02c744",
   "metadata": {
    "id": "EvyAINs9ZOmJ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d69a0d",
   "metadata": {
    "id": "wWLkKoKjZSoC"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5e4be",
   "metadata": {
    "id": "LWS-vvNaZDag"
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ee51c",
   "metadata": {
    "id": "Lkdl8VsBbZOu"
   },
   "source": [
    "## Visualice los resultados del entrenamiento\n",
    "\n",
    "Después de aplicar el aumento de datos y `tf.keras.layers.Dropout`, hay menos sobreajuste que antes, y la precisión de entrenamiento y validación están más alineadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff68c2f",
   "metadata": {
    "id": "dduoLfKsZVIA"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368ab4d",
   "metadata": {
    "id": "dtv5VbaVb-3W"
   },
   "source": [
    "## Predecir con nuevos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f159f4f",
   "metadata": {
    "id": "10buWpJbcCQz"
   },
   "source": [
    "Utilice su modelo para clasificar una imagen que no estaba incluida en los conjuntos de entrenamiento o validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82412b05",
   "metadata": {
    "id": "NKgMZ4bDcHf7"
   },
   "source": [
    "Nota: El aumento de datos y abandonar capas estarán inactivos en el momento de hacer inferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d4ed50",
   "metadata": {
    "id": "dC40sRITBSsQ"
   },
   "outputs": [],
   "source": [
    "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
    "sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    sunflower_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646627b",
   "metadata": {
    "id": "aOc3PZ2N2r18"
   },
   "source": [
    "## Utilice TensorFlow Lite\n",
    "\n",
    "TensorFlow Lite es un conjunto de herramientas que permite el aprendizaje automático en el dispositivo ayudando a los desarrolladores a ejecutar sus modelos en dispositivos móviles, integrados y edge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abb848",
   "metadata": {
    "id": "cThu25rh4LPP"
   },
   "source": [
    "### Convertir el modelo secuencial Keras en un modelo de TensorFlow Lite\n",
    "\n",
    "Para utilizar el modelo entrenado con aplicaciones en el dispositivo, primero [convertirlo](https://www.tensorflow.org/lite/models/convert) a un formato de modelo más pequeño y eficiente llamado modelo [TensorFlow Lite](https://www.tensorflow.org/lite/).\n",
    "\n",
    "En este ejemplo, tome el modelo secuencial de Keras entrenado y utilice `tf.lite.TFLiteConverter.from_keras_model` para generar un modelo [TensorFlow Lite](https://www.tensorflow.org/lite/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989c273",
   "metadata": {
    "id": "mXo6ftuL2ufx"
   },
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b01b1b",
   "metadata": {
    "id": "4R26OU4gGKhh"
   },
   "source": [
    "El modelo TensorFlow Lite que guardó en el paso anterior puede contener varias firmas de funciones. La API de conversión de modelos de Keras utiliza automáticamente la firma predeterminada. Obtenga más información sobre [firmas de TensorFlow Lite](https://www.tensorflow.org/lite/guide/signatures)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a52c6",
   "metadata": {
    "id": "VyOckJu6Rs-i"
   },
   "source": [
    "# Aumentación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d6002",
   "metadata": {
    "id": "PxIOE5RnSQtj"
   },
   "source": [
    "## Descripción general\n",
    "\n",
    "Este tutorial muestra la aumentación de datos: una técnica para aumentar la diversidad de su conjunto de entrenamiento aplicando transformaciones aleatorias (pero realistas), como la rotación de imágenes.\n",
    "\n",
    "Aprenderá a aplicar la aumentación de datos de dos maneras:\n",
    "\n",
    "- Usar las capas de preprocesamiento Keras, como `tf.keras.layers.Resizing`, `tf.keras.layers.Rescaling`, `tf.keras.layers.RandomFlip`, y `tf.keras.layers.RandomRotation`.\n",
    "- Usar los métodos `tf.image`, como `tf.image.flip_left_right`, `tf.image.rgb_to_grayscale`, `tf.image.adjust_brightness`, `tf.image.central_crop`, y `tf.image.stateless_random*`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f68e28",
   "metadata": {
    "id": "-UxHAqXmSXN5"
   },
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb20638",
   "metadata": {
    "id": "C2Q5rPenTAJP"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59079ffb",
   "metadata": {
    "id": "Ydx3SSoF4wpG"
   },
   "source": [
    "## Descargar un conjunto de datos\n",
    "\n",
    "Este tutorial usa el conjunto de datos [tf_flowers](https://www.tensorflow.org/datasets/catalog/tf_flowers). Para mayor comodidad, descargue el conjunto de datos utilizando [Conjuntos de datos de TensorFlow](https://www.tensorflow.org/datasets). Si desea conocer otras formas de importar datos, consulte el tutorial [cargar imágenes](https://www.tensorflow.org/tutorials/load_data/images).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645fd943",
   "metadata": {
    "id": "ytHhsYmO52zy"
   },
   "outputs": [],
   "source": [
    "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14611a",
   "metadata": {
    "id": "MjxEJtCwsnmm"
   },
   "source": [
    "El conjunto de datos de flores tiene cinco clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c44ff",
   "metadata": {
    "id": "wKwx7vQuspxz"
   },
   "outputs": [],
   "source": [
    "num_classes = metadata.features['label'].num_classes\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e17297",
   "metadata": {
    "id": "zZAQW44949uw"
   },
   "source": [
    "Recuperemos una imagen del conjunto de datos y usémosla para demostrar la aumentación de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd2437",
   "metadata": {
    "id": "kXlx1lCr5Bip"
   },
   "outputs": [],
   "source": [
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "image, label = next(iter(train_ds))\n",
    "_ = plt.imshow(image)\n",
    "_ = plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87fce6",
   "metadata": {
    "id": "vdJ6XA4q2nqK"
   },
   "source": [
    "## Usar las capas de preprocesamiento Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2d7e9",
   "metadata": {
    "id": "GRMPnfzBB2hw"
   },
   "source": [
    "### Redimensionar y reescalar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07712744",
   "metadata": {
    "id": "jhG7gSWmUMJx"
   },
   "source": [
    "Puede usar las capas de preprocesamiento de Keras para redimensionar sus imágenes de forma consistente (con `tf.keras.layers.Resizing`), y para reescalar los valores de los pixeles (con `tf.keras.layers.Rescaling`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aace08",
   "metadata": {
    "id": "jMM3b85e3yhd"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 180\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "  layers.Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4a233",
   "metadata": {
    "id": "4z8AV1WgnYNW"
   },
   "source": [
    "Nota: La capa de reescalado anterior estandariza los valores de los pixeles al rango `[0, 1]`. Si en su lugar quisiera que fuera `[-1, 1]`, pudiese escribir `tf.keras.layers.Rescaling(1./127.5, offset=-1)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2b4c1",
   "metadata": {
    "id": "MQiTwsHJDHAD"
   },
   "source": [
    "Puede visualizar el resultado de aplicar estas capas a una imagen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef1fe5",
   "metadata": {
    "id": "X9OLuR1bC1Pd"
   },
   "outputs": [],
   "source": [
    "result = resize_and_rescale(image)\n",
    "_ = plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83f5fd9",
   "metadata": {
    "id": "yxAMg8Zql5lw"
   },
   "source": [
    "Compruebe que los píxeles se encuentran en el intervalo `[0, 1]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3271dc6",
   "metadata": {
    "id": "DPTB8IQmSeKM"
   },
   "outputs": [],
   "source": [
    "print(\"Min and max pixel values:\", result.numpy().min(), result.numpy().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4047a8",
   "metadata": {
    "id": "fL6M7fuivAw4"
   },
   "source": [
    "### Aumentación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7440836",
   "metadata": {
    "id": "SL4Suj46ScfU"
   },
   "source": [
    "También puede usar las capas de preprocesamiento de Keras para aumentar datos, como `tf.keras.layers.RandomFlip` y `tf.keras.layers.RandomRotation`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256ee50",
   "metadata": {
    "id": "V-4PugTE-4sl"
   },
   "source": [
    "Creemos unas cuantas capas de preprocesamiento y apliquémoslas repetidamente a la misma imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258dd15e",
   "metadata": {
    "id": "Svu_5yfa_Jb7"
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d9e502",
   "metadata": {
    "id": "kfzEuaNg69iU"
   },
   "outputs": [],
   "source": [
    "# Add the image to a batch.\n",
    "image = tf.cast(tf.expand_dims(image, 0), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aaf121",
   "metadata": {
    "id": "eR4wwi5Q_UZK"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  augmented_image = data_augmentation(image)\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(augmented_image[0])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795fd9e",
   "metadata": {
    "id": "jA17pEeS_2_-"
   },
   "source": [
    "Puede usar diversas capas de preprocesamiento para aumentar datos, como `tf.keras.layers.RandomContrast`, `tf.keras.layers.RandomCrop`, `tf.keras.layers.RandomZoom`, y otras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed309b",
   "metadata": {
    "id": "GG5RhIJtE0ng"
   },
   "source": [
    "### Dos opciones para usar las capas de preprocesamiento de Keras\n",
    "\n",
    "Hay dos formas de usar estas capas de preprocesamiento, con importantes concesiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67375289",
   "metadata": {
    "id": "B2X3JTeY_vfv"
   },
   "source": [
    "#### Aplicar las capas de preprocesamiento a su conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d635f4",
   "metadata": {
    "id": "r1Bt7w5VhVDY"
   },
   "outputs": [],
   "source": [
    "aug_ds = train_ds.map(\n",
    "  lambda x, y: (resize_and_rescale(x, training=True), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732398cb",
   "metadata": {
    "id": "HKqeahG2hVdV"
   },
   "source": [
    "Con este enfoque, se usa `Dataset.map` para crear un conjunto de datos que produzca lotes de imágenes aumentadas. En este caso:\n",
    "\n",
    "- La aumentación de datos se producirá de forma asíncrona en la CPU y no se bloqueará. Puede superponer el entrenamiento de su modelo en la GPU con el preprocesamiento de datos, usando `Dataset.prefetch`, que se muestra a continuación.\n",
    "- En este caso, las capas de preprocesamiento no se exportarán con el modelo cuando llame a `Model.save`. Deberá adjuntarlas a su modelo antes de guardarlo o reimplementarlas en el lado del servidor. Después del entrenamiento, puede adjuntar las capas de preprocesamiento antes de exportarlas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa8ccc",
   "metadata": {
    "id": "cgj51k9J7jfc"
   },
   "source": [
    "Puede encontrar un ejemplo de la primera opción en el tutorial [Clasificación de imágenes](classification.ipynb). Vamos a demostrar aquí la segunda opción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0432cc56",
   "metadata": {
    "id": "31YwMQdrXKBP"
   },
   "source": [
    "### Aplicar las capas de preprocesamiento a los conjuntos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df2f76",
   "metadata": {
    "id": "WUgW-2LOGiOT"
   },
   "source": [
    "Configure los conjuntos de datos de entrenamiento, validación y prueba con las capas de preprocesamiento Keras que creó anteriormente. También configurará los conjuntos de datos para mejorar el rendimiento, usando lecturas paralelas y preextracción en búfer para obtener lotes del disco sin que la E/S se bloquee. (Obtenga más información sobre el rendimiento de los conjuntos de datos en la guía [Mejor rendimiento con la API tf.data](https://www.tensorflow.org/guide/data_performance))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc41ca7",
   "metadata": {
    "id": "eI7VdyqK767y"
   },
   "source": [
    "Nota: La aumentación de datos sólo debe aplicarse al conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ebd5db",
   "metadata": {
    "id": "R5fGVMqlFxF7"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "  # Resize and rescale all datasets.\n",
    "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n",
    "              num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(1000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc2041",
   "metadata": {
    "id": "N86SFGMBHcx-"
   },
   "outputs": [],
   "source": [
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "val_ds = prepare(val_ds)\n",
    "test_ds = prepare(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4df3a5",
   "metadata": {
    "id": "9gplDz4ZV6kk"
   },
   "source": [
    "### Entrenar un modelo\n",
    "\n",
    "Para completar, ahora entrenará un modelo usando los conjuntos de datos que acaba de preparar.\n",
    "\n",
    "El modelo [Secuencial](https://www.tensorflow.org/guide/keras/sequential_model) consta de tres bloques de convolución (`tf.keras.layers.Conv2D`) con una capa de agrupamiento máximo (`tf.keras.layers.MaxPooling2D`) en cada uno de ellos. Hay una capa (`tf.keras.layers.Dense`) totalmente conectada (`tf.keras.layers.Dense`) con 128 unidades que se activa mediante una función de activación ReLU (`'relu'`). Este modelo no se ha ajustado para obtener precisión (la meta es mostrarle la mecánica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93eab5",
   "metadata": {
    "id": "IODSymGhq9N6"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4709a0",
   "metadata": {
    "id": "86454855f7d9"
   },
   "source": [
    "Seleccione el optimizador `tf.keras.optimizers.Adam` y la función de pérdida `tf.keras.losses.SparseCategoricalCrossentropy`. Para ver la precisión del entrenamiento y la validación de cada época de entrenamiento, pase el argumento `metrics` a `Model.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e8f624",
   "metadata": {
    "id": "ZnRJr95WY68k"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb88ca1b",
   "metadata": {
    "id": "976f718cabc8"
   },
   "source": [
    "Entrene por algunas épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc09aa",
   "metadata": {
    "id": "i_sDl9uZY9Mh"
   },
   "outputs": [],
   "source": [
    "epochs=5\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa00165",
   "metadata": {
    "id": "V9PSf4qgiQJG"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fa0637",
   "metadata": {
    "id": "0BkRvvsXb6SI"
   },
   "source": [
    "### Aumentación de datos personalizados\n",
    "\n",
    "También puede crear capas de aumentación de datos personalizadas.\n",
    "\n",
    "Esta sección del tutorial muestra dos formas de hacerlo:\n",
    "\n",
    "- En primer lugar, creará una capa `tf.keras.layers.Lambda`. Esta es una buena manera de escribir código conciso.\n",
    "- Luego, escribirá una nueva capa por [subclaseado](https://www.tensorflow.org/guide/keras/custom_layers_and_models), lo que le da más control.\n",
    "\n",
    "Ambas capas invertirán aleatoriamente los colores de una imagen, según cierta probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae101b",
   "metadata": {
    "id": "nMxEhIVXmAH0"
   },
   "outputs": [],
   "source": [
    "def random_invert_img(x, p=0.5):\n",
    "  if  tf.random.uniform([]) < p:\n",
    "    x = (255-x)\n",
    "  else:\n",
    "    x\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11df183",
   "metadata": {
    "id": "C0huNpxdmDKu"
   },
   "outputs": [],
   "source": [
    "def random_invert(factor=0.5):\n",
    "  return layers.Lambda(lambda x: random_invert_img(x, factor))\n",
    "\n",
    "random_invert = random_invert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd0fcd",
   "metadata": {
    "id": "wAcOluP0TNG6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  augmented_image = random_invert(image)\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a2bce",
   "metadata": {
    "id": "Xd9XG2PLM5ZJ"
   },
   "source": [
    "En seguida, implemente una capa personalizada a través de [subclaseado](https://www.tensorflow.org/guide/keras/custom_layers_and_models):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cdee18",
   "metadata": {
    "id": "d11eExc-Ke-7"
   },
   "outputs": [],
   "source": [
    "class RandomInvert(layers.Layer):\n",
    "  def __init__(self, factor=0.5, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.factor = factor\n",
    "\n",
    "  def call(self, x):\n",
    "    return random_invert_img(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9db45",
   "metadata": {
    "id": "qX-VQgkRL6fc"
   },
   "outputs": [],
   "source": [
    "_ = plt.imshow(RandomInvert()(image)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4435bf",
   "metadata": {
    "id": "B0nmllnXZO6T"
   },
   "source": [
    "Ambas capas pueden usarse como se describe en las opciones 1 y 2 anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891bb17",
   "metadata": {
    "id": "j7-k__2dAfX6"
   },
   "source": [
    "## Usar tf.image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e5ee1",
   "metadata": {
    "id": "NJco2x35EAMs"
   },
   "source": [
    "Las utilidades de preprocesamiento Keras anteriores son convenientes. Pero, para un control más fino, puede escribir sus propias canalizaciones o capas de aumentación de datos usando `tf.data` y `tf.image` (también puede consultar [Complemento de TensorFlow Imagen: Operaciones](https://www.tensorflow.org/addons/tutorials/image_ops) y [TensorFlow I/O: Conversiones de Espacio de Color](https://www.tensorflow.org/io/tutorials/colorspace).)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f081b3",
   "metadata": {
    "id": "xR1RvjYkdd_i"
   },
   "source": [
    "Dado que el conjunto de datos de flores se configuró previamente con la aumentación de datos, vamos a reimportarlo para empezar de cero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad932195",
   "metadata": {
    "id": "JB-lAS0z9ZJY"
   },
   "outputs": [],
   "source": [
    "(train_ds, val_ds, test_ds), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f9e5d",
   "metadata": {
    "id": "rQ3pqBTS9hNj"
   },
   "source": [
    "Recupere una imagen con la que trabajar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6968a",
   "metadata": {
    "id": "dDsPaAi8de_j"
   },
   "outputs": [],
   "source": [
    "image, label = next(iter(train_ds))\n",
    "_ = plt.imshow(image)\n",
    "_ = plt.title(get_label_name(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c0096c",
   "metadata": {
    "id": "chelxcPtFiTF"
   },
   "source": [
    "Usemos la siguiente función para visualizar y comparar las imágenes original y aumentada una al lado de la otra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61848b54",
   "metadata": {
    "id": "sN1ykjJCHikc"
   },
   "outputs": [],
   "source": [
    "def visualize(original, augmented):\n",
    "  fig = plt.figure()\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.title('Original image')\n",
    "  plt.imshow(original)\n",
    "\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.title('Augmented image')\n",
    "  plt.imshow(augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff26ac5",
   "metadata": {
    "id": "C5X4ijQYHmlt"
   },
   "source": [
    "### Aumentación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5af2d",
   "metadata": {
    "id": "RRD9oujLHo6c"
   },
   "source": [
    "#### Invertir una imagen\n",
    "\n",
    "Invierta una imagen vertical u horizontalmente con `tf.image.flip_left_right`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f8b73e",
   "metadata": {
    "id": "1ZjVI24nIH0S"
   },
   "outputs": [],
   "source": [
    "flipped = tf.image.flip_left_right(image)\n",
    "visualize(image, flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0471c",
   "metadata": {
    "id": "6iD_lLibIL9q"
   },
   "source": [
    "#### Aplicar escala de grises a una imagen\n",
    "\n",
    "Puede aplicar escala de grises a una imagen con `tf.image.rgb_to_grayscale`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa8698",
   "metadata": {
    "id": "ikaMj0guIRtL"
   },
   "outputs": [],
   "source": [
    "grayscaled = tf.image.rgb_to_grayscale(image)\n",
    "visualize(image, tf.squeeze(grayscaled))\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03088d5",
   "metadata": {
    "id": "f-5yjIs4IZ7v"
   },
   "source": [
    "#### Saturar una imagen\n",
    "\n",
    "Sature una imagen con `tf.image.adjust_saturation` indicando un factor de saturación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784f359",
   "metadata": {
    "id": "PHz-NosiInmz"
   },
   "outputs": [],
   "source": [
    "saturated = tf.image.adjust_saturation(image, 3)\n",
    "visualize(image, saturated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21f0c6",
   "metadata": {
    "id": "FWXiy8qfIqdC"
   },
   "source": [
    "#### Cambiar el brillo de la imagen\n",
    "\n",
    "Cambie el brillo de la imagen con `tf.image.adjust_brightness` indicando un factor de brillo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b9094",
   "metadata": {
    "id": "1hdG-j46I0nJ"
   },
   "outputs": [],
   "source": [
    "bright = tf.image.adjust_brightness(image, 0.4)\n",
    "visualize(image, bright)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d4b1d",
   "metadata": {
    "id": "vjEOFEITJOr2"
   },
   "source": [
    "#### Recortar una imagen al centro\n",
    "\n",
    "Recorte la imagen desde el centro hasta la parte de la imagen que desee usando `tf.image.central_crop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe3163",
   "metadata": {
    "id": "RWkK5GFHJUKT"
   },
   "outputs": [],
   "source": [
    "cropped = tf.image.central_crop(image, central_fraction=0.5)\n",
    "visualize(image, cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07083497",
   "metadata": {
    "id": "unt76GebI3Gc"
   },
   "source": [
    "#### Girar una imagen\n",
    "\n",
    "Gire una imagen 90 grados con `tf.image.rot90`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a01eee0",
   "metadata": {
    "id": "b19KuAhkJKR-"
   },
   "outputs": [],
   "source": [
    "rotated = tf.image.rot90(image)\n",
    "visualize(image, rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f9142",
   "metadata": {
    "id": "5CPP0vEKB56X"
   },
   "source": [
    "### Transformaciones aleatorias\n",
    "\n",
    "Advertencia: Existen dos conjuntos de operaciones de imagen aleatoria: `tf.image.random*` y `tf.image.stateless_random*`. Se desaconseja encarecidamente usar las operaciones `tf.image.random*`, ya que usan los antiguos RNG de TF 1.x. En su lugar, use las operaciones de imagen aleatoria introducidas en este tutorial. Para más información, consulte [Generación de números aleatorios](../../guide/random_numbers.ipynb).\n",
    "\n",
    "Aplicar transformaciones aleatorias a las imágenes puede ayudar aún más a generalizar y ampliar el conjunto de datos. La API actual `tf.image` ofrece ocho operaciones (ops) de imagen aleatorias de este tipo:\n",
    "\n",
    "- [`tf.image.stateless_random_brightness`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_brightness)\n",
    "- [`tf.image.stateless_random_contrast`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_contrast)\n",
    "- [`tf.image.stateless_random_crop`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_crop)\n",
    "- [`tf.image.stateless_random_flip_left_right`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_flip_left_right)\n",
    "- [`tf.image.stateless_random_flip_up_down`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_flip_up_down)\n",
    "- [`tf.image.stateless_random_hue`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_hue)\n",
    "- [`tf.image.stateless_random_jpeg_quality`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_jpeg_quality)\n",
    "- [`tf.image.stateless_random_saturation`](https://www.tensorflow.org/api_docs/python/tf/image/stateless_random_saturation)\n",
    "\n",
    "Estas ops de imagen aleatoria son puramente funcionales: la salida sólo depende de la entrada. Esto hace que sean fáciles de usar en canalizaciones de entrada deterministas de alto rendimiento. Requieren que se introduzca un valor `seed` en cada paso. Dada la misma `seed`, devuelven los mismos resultados independientemente de cuántas veces se les llame.\n",
    "\n",
    "Nota: `seed` es un `Tensor` de forma `(2,)` cuyos valores son cualesquiera enteros.\n",
    "\n",
    "En las siguientes secciones, usted:\n",
    "\n",
    "1. Repasará ejemplos de cómo usar operaciones de imagen aleatorias para transformar una imagen.\n",
    "2. Demuestre cómo aplicar transformaciones aleatorias a un conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ae075",
   "metadata": {
    "id": "251Wy-MqE4La"
   },
   "source": [
    "#### Modificar aleatoriamente el brillo de la imagen\n",
    "\n",
    "Modifique aleatoriamente el brillo de `image` usando `tf.image.stateless_random_brightness` al dar un factor de brillo y `seed`. El factor de brillo se elige aleatoriamente en el rango `[-max_delta, max_delta)` y se asocia a la `seed` dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fbcaa7",
   "metadata": {
    "id": "-fFd1kh7Fr-_"
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "  seed = (i, 0)  # tuple of size (2,)\n",
    "  stateless_random_brightness = tf.image.stateless_random_brightness(\n",
    "      image, max_delta=0.95, seed=seed)\n",
    "  visualize(image, stateless_random_brightness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b216b10d",
   "metadata": {
    "id": "uLaDEmooUfYJ"
   },
   "source": [
    "#### Cambiar aleatoriamente el contraste de la imagen\n",
    "\n",
    "Cambie aleatoriamente el contraste de `image` usando `tf.image.stateless_random_contrast` al dar un intervalo de contraste y `seed`. El rango de contraste se elige aleatoriamente en el intervalo `[lower, upper]` y se asocia con la `seed` dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd819d2",
   "metadata": {
    "id": "GmcYoQHaUoke"
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "  seed = (i, 0)  # tuple of size (2,)\n",
    "  stateless_random_contrast = tf.image.stateless_random_contrast(\n",
    "      image, lower=0.1, upper=0.9, seed=seed)\n",
    "  visualize(image, stateless_random_contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac076ce6",
   "metadata": {
    "id": "wxb-MP-KVPNz"
   },
   "source": [
    "#### Recortar una imagen al azar\n",
    "\n",
    "Recorte aleatoriamente `imagen` usando `tf.image.stateless_random_crop` al dar un `size` y `seed` del objetivo. La parte que se recorta de `image` está en un punto elegido aleatoriamente y se asocia a la `seed` dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8596b7",
   "metadata": {
    "id": "vtZQbUw0VOm5"
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "  seed = (i, 0)  # tuple of size (2,)\n",
    "  stateless_random_crop = tf.image.stateless_random_crop(\n",
    "      image, size=[210, 300, 3], seed=seed)\n",
    "  visualize(image, stateless_random_crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b227189a",
   "metadata": {
    "id": "isrM-MZtpxTq"
   },
   "source": [
    "### Aplicar la aumentación a un conjunto de datos\n",
    "\n",
    "En primer lugar, descarguemos de nuevo el conjunto de datos de imágenes por si se han modificado en las secciones anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebcc5b0",
   "metadata": {
    "id": "xC80NQP809Uo"
   },
   "outputs": [],
   "source": [
    "(train_datasets, val_ds, test_ds), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c92724",
   "metadata": {
    "id": "SMo9HTDV0Gaz"
   },
   "source": [
    "A continuación, defina una función de utilidad para cambiar el tamaño y la escala de las imágenes. Esta función se usará para unificar el tamaño y la escala de las imágenes del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b560476",
   "metadata": {
    "id": "1JKmx06lfcFr"
   },
   "outputs": [],
   "source": [
    "def resize_and_rescale(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "  image = (image / 255.0)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d91ce",
   "metadata": {
    "id": "M7OpE_-jWq-I"
   },
   "source": [
    "Definamos también la función `augment` que puede aplicar las transformaciones aleatorias a las imágenes. Esta función se usará sobre el conjunto de datos en el siguiente paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f2410",
   "metadata": {
    "id": "KitLdvlpVxPa"
   },
   "outputs": [],
   "source": [
    "def augment(image_label, seed):\n",
    "  image, label = image_label\n",
    "  image, label = resize_and_rescale(image, label)\n",
    "  image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 6, IMG_SIZE + 6)\n",
    "  # Make a new seed.\n",
    "  new_seed = tf.random.split(seed, num=1)[0, :]\n",
    "  # Random crop back to the original size.\n",
    "  image = tf.image.stateless_random_crop(\n",
    "      image, size=[IMG_SIZE, IMG_SIZE, 3], seed=seed)\n",
    "  # Random brightness.\n",
    "  image = tf.image.stateless_random_brightness(\n",
    "      image, max_delta=0.5, seed=new_seed)\n",
    "  image = tf.clip_by_value(image, 0, 1)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0062e",
   "metadata": {
    "id": "SlXRsVp70hg8"
   },
   "source": [
    "#### Opción 1: Usar tf.data.experimental.Counter\n",
    "\n",
    "Cree un objeto `tf.data.experimental.Counter` (llamémoslo `counter`) y `Dataset.zip` se llamará el conjunto de datos con `(counter, counter)`. Esto asegurará que cada imagen del conjunto de datos se asocie con un valor único (de forma `(2,)`) basado en `counter` que más tarde puede ser pasado a la función `augment` como el valor `seed` para transformaciones aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf72959",
   "metadata": {
    "id": "SZ6Qq0IWznfi"
   },
   "outputs": [],
   "source": [
    "# Create a `Counter` object and `Dataset.zip` it together with the training set.\n",
    "counter = tf.data.experimental.Counter()\n",
    "train_ds = tf.data.Dataset.zip((train_datasets, (counter, counter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c221da6",
   "metadata": {
    "id": "eF9ybVQ94X9f"
   },
   "source": [
    "Mapee la función `augment` al conjunto de datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e5161d",
   "metadata": {
    "id": "wQK9BDKk1_3N"
   },
   "outputs": [],
   "source": [
    "train_ds = (\n",
    "    train_ds\n",
    "    .shuffle(1000)\n",
    "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ca632",
   "metadata": {
    "id": "3AQoyA-k3ELk"
   },
   "outputs": [],
   "source": [
    "val_ds = (\n",
    "    val_ds\n",
    "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538cae92",
   "metadata": {
    "id": "p2IQN3NN3G_M"
   },
   "outputs": [],
   "source": [
    "test_ds = (\n",
    "    test_ds\n",
    "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647e56b",
   "metadata": {
    "id": "pvTVY8BY2LpD"
   },
   "source": [
    "#### Opción 2: Usar tf.random.Generator\n",
    "\n",
    "- Cree un objeto `tf.random.Generator` con un valor inicial `seed`. Si se llama a la función `make_seeds` sobre el mismo objeto generador, siempre se devuelve un nuevo valor `seed` único.\n",
    "- Defina una función contenedora que: 1) llame a la función `make_seeds`; y 2) pase el valor `seed` recién generado a la función `augment` para transformaciones aleatorias.\n",
    "\n",
    "Nota: Los objetos `tf.random.Generator` almacenan el estado del RNG en una `tf.Variable`, lo que significa que puede guardarse como un [checkpoint](../../guide/checkpoint.ipynb) o en un [SavedModel](../../guide/saved_model.ipynb). Para más detalles, consulte [Generación de números aleatorios](../../guide/random_numbers.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d6863",
   "metadata": {
    "id": "BQDvedZ33eAy"
   },
   "outputs": [],
   "source": [
    "# Create a generator.\n",
    "rng = tf.random.Generator.from_seed(123, alg='philox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07479946",
   "metadata": {
    "id": "eDEkO1nt2ta0"
   },
   "outputs": [],
   "source": [
    "# Create a wrapper function for updating seeds.\n",
    "def f(x, y):\n",
    "  seed = rng.make_seeds(2)[0]\n",
    "  image, label = augment((x, y), seed)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67044e2",
   "metadata": {
    "id": "PyPC4vUM4MT0"
   },
   "source": [
    "Mapee la función contenedora `f` al conjunto de datos de entrenamiento, y la función `resize_and_rescale` a los conjuntos de validación y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f53e94",
   "metadata": {
    "id": "Pu2uB7k12xKw"
   },
   "outputs": [],
   "source": [
    "train_ds = (\n",
    "    train_datasets\n",
    "    .shuffle(1000)\n",
    "    .map(f, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9950a3",
   "metadata": {
    "id": "e6caldPi2HAP"
   },
   "outputs": [],
   "source": [
    "val_ds = (\n",
    "    val_ds\n",
    "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d80a1",
   "metadata": {
    "id": "ceaCdJnh2I-r"
   },
   "outputs": [],
   "source": [
    "test_ds = (\n",
    "    test_ds\n",
    "    .map(resize_and_rescale, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f452e3",
   "metadata": {
    "id": "hKwCA6AOjTrc"
   },
   "source": [
    "Estos conjuntos de datos pueden usarse ahora para entrenar un modelo como se ha mostrado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc98c16",
   "metadata": {
    "id": "YypDihDlj0no"
   },
   "source": [
    "## Siguientes pasos\n",
    "\n",
    "Este tutorial demostró la aumentación de datos usando capas de preprocesamiento Keras y `tf.image`.\n",
    "\n",
    "- Para aprender a incluir capas de preprocesamiento dentro de su modelo, consulte el tutorial [Clasificación de imágenes](classification.ipynb).\n",
    "- También puede interesarle aprender cómo las capas de preprocesamiento pueden ayudarle a clasificar texto, como se muestra en el tutorial [Clasificación básica de texto](../keras/text_classification.ipynb).\n",
    "- Puede aprender más sobre `tf.data` en esta [guía](../../guide/data.ipynb), y puede aprender a configurar sus canalizaciones de entrada para mejorar el rendimiento [aquí](../../guide/data_performance.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133766f",
   "metadata": {
    "id": "TBFXQGKYUc4X"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f7cf3",
   "metadata": {
    "cellView": "form",
    "id": "1z4xy2gTUc4a"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dead5b0",
   "metadata": {
    "id": "FE7KNzPPVrVV"
   },
   "source": [
    "# Dogs vs Cats Image Classification With Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41beeaaf",
   "metadata": {
    "id": "gN7G9GFmVrVY"
   },
   "source": [
    "In this tutorial, we will discuss how to classify images into pictures of cats or pictures of dogs. We'll build an image classifier using `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`.\n",
    "\n",
    "## Specific concepts that will be covered:\n",
    "In the process, we will build practical experience and develop intuition around the following concepts\n",
    "\n",
    "* Building _data input pipelines_ using the `tf.keras.preprocessing.image.ImageDataGenerator` class — How can we efficiently work with data on disk to interface with our model?\n",
    "* _Overfitting_ - what is it, how to identify it, and how can we prevent it?\n",
    "* _Data Augmentation_ and _Dropout_ - Key techniques to fight overfitting in computer vision tasks that we will incorporate into our data pipeline and image classifier model.\n",
    "\n",
    "## We will follow the general machine learning workflow:\n",
    "\n",
    "1. Examine and understand data\n",
    "2. Build an input pipeline\n",
    "3. Build our model\n",
    "4. Train our model\n",
    "5. Test our model\n",
    "6. Improve our model/Repeat the process\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Before you begin**\n",
    "\n",
    "Before running the code in this notebook, reset the runtime by going to **Runtime -> Reset all runtimes** in the menu above. If you have been working through several notebooks, this will help you avoid reaching Colab's memory limits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2042f",
   "metadata": {
    "id": "zF9uvbXNVrVY"
   },
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008bd553",
   "metadata": {
    "id": "VddxeYBEVrVZ"
   },
   "source": [
    "Let's start by importing required packages:\n",
    "\n",
    "*   os — to read files and directory structure\n",
    "*   numpy — for some matrix math outside of TensorFlow\n",
    "*   matplotlib.pyplot — to plot the graph and display images in our training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41732b",
   "metadata": {
    "id": "in3OdvpUG_9_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c15724",
   "metadata": {
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42420a8f",
   "metadata": {
    "id": "ede3_kbeHOjR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97c9ce",
   "metadata": {
    "id": "UZZI6lNkVrVm"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7008525",
   "metadata": {
    "id": "DPHx8-t-VrVo"
   },
   "source": [
    "To build our image classifier, we begin by downloading the dataset. The dataset we are using is a filtered version of <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs. Cats</a> dataset from Kaggle (ultimately, this dataset is provided by Microsoft Research).\n",
    "\n",
    "In previous Colabs, we've used <a href=\"https://www.tensorflow.org/datasets\" target=\"_blank\">TensorFlow Datasets</a>, which is a very easy and convenient way to use datasets. In this Colab however, we will make use of the class `tf.keras.preprocessing.image.ImageDataGenerator` which will read data from disk. We therefore need to directly download *Dogs vs. Cats* from a URL and unzip it to the Colab filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ccf22",
   "metadata": {
    "id": "OYmOylPlVrVt"
   },
   "outputs": [],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "\n",
    "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37da9c",
   "metadata": {
    "id": "Giv0wMQzVrVw"
   },
   "source": [
    "The dataset we have downloaded has following directory structure.\n",
    "\n",
    "<pre style=\"font-size: 10.0pt; font-family: Arial; line-height: 2; letter-spacing: 1.0pt;\" >\n",
    "<b>cats_and_dogs_filtered</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
    "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
    "|__ <b>validation</b>\n",
    "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
    "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8482566",
   "metadata": {
    "id": "VpmywIlsVrVx"
   },
   "source": [
    "We'll now assign variables with the proper file path for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed142415",
   "metadata": {
    "id": "sRucI3QqVrVy"
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filterted_extracted/cats_and_dogs_filtered')\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6015e03",
   "metadata": {
    "id": "Utv3nryxVrV0"
   },
   "outputs": [],
   "source": [
    "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f666c0d3",
   "metadata": {
    "id": "ZdrHHTy2VrV3"
   },
   "source": [
    "### Understanding our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59800b62",
   "metadata": {
    "id": "LblUYjl-VrV3"
   },
   "source": [
    "Let's look at how many cats and dogs images we have in our training and validation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbfadc0",
   "metadata": {
    "id": "vc4u8e9hVrV4"
   },
   "outputs": [],
   "source": [
    "num_cats_tr = len(os.listdir(train_cats_dir))\n",
    "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
    "\n",
    "num_cats_val = len(os.listdir(validation_cats_dir))\n",
    "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "total_train = num_cats_tr + num_dogs_tr\n",
    "total_val = num_cats_val + num_dogs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4cd5e",
   "metadata": {
    "id": "g4GGzGt0VrV7"
   },
   "outputs": [],
   "source": [
    "print('total training cat images:', num_cats_tr)\n",
    "print('total training dog images:', num_dogs_tr)\n",
    "\n",
    "print('total validation cat images:', num_cats_val)\n",
    "print('total validation dog images:', num_dogs_val)\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941a8fe6",
   "metadata": {
    "id": "tdsI_L-NVrV_"
   },
   "source": [
    "# Setting Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008c601",
   "metadata": {
    "id": "8Lp-0ejxOtP1"
   },
   "source": [
    "For convenience, let us set up variables that will be used later while pre-processing our dataset and training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bfd98f",
   "metadata": {
    "id": "3NqNselLVrWA"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "IMG_SHAPE  = 150 # Our training data consists of images with width of 150 pixels and height of 150 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2cf09",
   "metadata": {
    "id": "RLciCR_FVrWH"
   },
   "source": [
    "After defining our generators for training and validation images, **flow_from_directory** method will load images from the disk and will apply rescaling and will resize them into required dimensions using single line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f6b75",
   "metadata": {
    "id": "UOoVpxFwVrWy"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96310067",
   "metadata": {
    "id": "Wn_QLciWVrWy"
   },
   "source": [
    "Overfitting often occurs when we have a small number of training examples. One way to fix this problem is to augment our dataset so that it has sufficient number and variety of training examples. Data augmentation takes the approach of generating more training data from existing training samples, by augmenting the samples through random transformations that yield believable-looking images. The goal is that at training time, your model will never see the exact same picture twice. This exposes the model to more aspects of the data, allowing it to generalize better.\n",
    "\n",
    "In **tf.keras** we can implement this using the same **ImageDataGenerator** class we used before. We can simply pass different transformations we would want to our dataset as a form of arguments and it will take care of applying it to the dataset during our training process.\n",
    "\n",
    "To start off, let's define a function that can display an image, so we can see the type of augmentation that has been performed. Then, we'll look at specific augmentations that we'll use during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9278c7",
   "metadata": {
    "id": "GBYLOFgOXPJ9"
   },
   "outputs": [],
   "source": [
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c47d3b4",
   "metadata": {
    "id": "rlVj6VqaVrW0"
   },
   "source": [
    "### Flipping the image horizontally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeddace",
   "metadata": {
    "id": "xcdvx4TVVrW1"
   },
   "source": [
    "We can begin by randomly applying horizontal flip augmentation to our dataset and seeing how individual images will look after the transformation. This is achieved by passing `horizontal_flip=True` as an argument to the `ImageDataGenerator` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0333bcd",
   "metadata": {
    "id": "Bi1_vHyBVrW2"
   },
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "\n",
    "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                               directory=train_dir,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(IMG_SHAPE,IMG_SHAPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5318f0",
   "metadata": {
    "id": "zJpRSxJ-VrW7"
   },
   "source": [
    "To see the transformation in action, let's take one sample image from our training set and repeat it five times. The augmentation will be randomly applied (or not) to each repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2e555",
   "metadata": {
    "id": "RrKGd_jjVrW7"
   },
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f481c70f",
   "metadata": {
    "id": "i7n9xcqCVrXB"
   },
   "source": [
    "### Rotating the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d3cab3",
   "metadata": {
    "id": "qXnwkzFuVrXB"
   },
   "source": [
    "The rotation augmentation will randomly rotate the image up to a specified number of degrees. Here, we'll set it to 45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f2f6be",
   "metadata": {
    "id": "1zip35pDVrXB"
   },
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)\n",
    "\n",
    "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                               directory=train_dir,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(IMG_SHAPE, IMG_SHAPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f800efc",
   "metadata": {
    "id": "deaqZLsfcZ15"
   },
   "source": [
    "To see the transformation in action, let's once again take a sample image from our training set and repeat it. The augmentation will be randomly applied (or not) to each repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a857921",
   "metadata": {
    "id": "kVoWh4OIVrXD"
   },
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13438eca",
   "metadata": {
    "id": "FOqGPL76VrXM"
   },
   "source": [
    "### Applying Zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b63e559",
   "metadata": {
    "id": "NvqXaD8BVrXN"
   },
   "source": [
    "We can also apply Zoom augmentation to our dataset, zooming images up to 50% randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665a235",
   "metadata": {
    "id": "tGNKLa_YVrXR",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)\n",
    "\n",
    "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                               directory=train_dir,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(IMG_SHAPE, IMG_SHAPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7575c1a",
   "metadata": {
    "id": "WgPWieSZcctO"
   },
   "source": [
    "One more time, take a sample image from our training set and repeat it. The augmentation will be randomly applied (or not) to each repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e721b5",
   "metadata": {
    "id": "VOvTs32FVrXU"
   },
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec973c4d",
   "metadata": {
    "id": "usS13KCNVrXd"
   },
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258a4223",
   "metadata": {
    "id": "OC8fIsalVrXd"
   },
   "source": [
    "We can apply all these augmentations, and even others, with just one line of code, by passing the augmentations as arguments with proper values.\n",
    "\n",
    "Here, we have applied rescale, rotation of 45 degrees, width shift, height shift, horizontal flip, and zoom augmentation to our training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b618f",
   "metadata": {
    "id": "gnr2xujaVrXe"
   },
   "outputs": [],
   "source": [
    "image_gen_train = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "                                                     class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5033406e",
   "metadata": {
    "id": "AW-pV5awVrXl"
   },
   "source": [
    "Let's visualize how a single image would look like five different times, when we pass these augmentations randomly to our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f18c8",
   "metadata": {
    "id": "z2m68eMhVrXm"
   },
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa0fef2",
   "metadata": {
    "id": "J8cUd7FXVrXq"
   },
   "source": [
    "### Creating Validation Data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717e0e3",
   "metadata": {
    "id": "a99fDBt7VrXr"
   },
   "source": [
    "Generally, we only apply data augmentation to our training examples, since the original images should be representative of what our model needs to manage. So, in this case we are only rescaling our validation images and converting them into batches using ImageDataGenerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b8bb5",
   "metadata": {
    "id": "54x0aNbKVrXr"
   },
   "outputs": [],
   "source": [
    "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                 directory=validation_dir,\n",
    "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
    "                                                 class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61a90e",
   "metadata": {
    "id": "b5Ej-HLGVrWZ"
   },
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e512b5",
   "metadata": {
    "id": "wEgW4i18VrWZ"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "The model consists of four convolution blocks with a max pool layer in each of them.\n",
    "\n",
    "Before the final Dense layers, we're also applying a Dropout probability of 0.5. It means that 50% of the values coming into the Dropout layer will be set to zero. This helps to prevent overfitting.\n",
    "\n",
    "Then we have a fully connected layer with 512 units, with a `relu` activation function. The model will output class probabilities for two classes — dogs and cats — using `softmax`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87592d",
   "metadata": {
    "cellView": "both",
    "id": "Evjf8jZk2zi-"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c95404",
   "metadata": {
    "id": "DADWLqMSJcH3"
   },
   "source": [
    "### Compiling the model\n",
    "\n",
    "As usual, we will use the `adam` optimizer. Since we output a softmax categorization, we'll use `sparse_categorical_crossentropy` as the loss function. We would also like to look at training and validation accuracy on each epoch as we train our network, so we are passing in the metrics argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9be22d",
   "metadata": {
    "id": "08rRJ0sn3Tb1"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc0b11",
   "metadata": {
    "id": "uurnCp_H4Hj9"
   },
   "source": [
    "### Model Summary\n",
    "\n",
    "Let's look at all the layers of our network using **summary** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fff17d",
   "metadata": {
    "id": "b66qAJF_4Jnw"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f9f7e",
   "metadata": {
    "id": "N06iqE8VVrWj"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17553d15",
   "metadata": {
    "id": "oub9RtoFVrWk"
   },
   "source": [
    "It's time we train our network.\n",
    "\n",
    "Since our batches are coming from a generator (`ImageDataGenerator`), we'll use `fit_generator` instead of `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c86ea",
   "metadata": {
    "id": "tk5NT1PW3j_P"
   },
   "outputs": [],
   "source": [
    "epochs=1\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2165bc5",
   "metadata": {
    "id": "ojJNteAGVrWo"
   },
   "source": [
    "### Visualizing results of the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a4583",
   "metadata": {
    "id": "LZPYT-EmVrWo"
   },
   "source": [
    "We'll now visualize the results we get after training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097e38ec",
   "metadata": {
    "id": "8CfngybnFHQR"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa63a7b",
   "metadata": {
    "id": "TBFXQGKYUc4X"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044e170",
   "metadata": {
    "cellView": "form",
    "id": "1z4xy2gTUc4a"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a54e82",
   "metadata": {
    "id": "FE7KNzPPVrVV"
   },
   "source": [
    "# Image Classification using tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a0cc99",
   "metadata": {
    "id": "KwQtSOz0VrVX"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c04_exercise_flowers_with_data_augmentation_solution.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c04_exercise_flowers_with_data_augmentation_solution.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7499c92",
   "metadata": {
    "id": "gN7G9GFmVrVY"
   },
   "source": [
    "In this Colab you will classify images of flowers. You will build an image classifier using `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be17255",
   "metadata": {
    "id": "zF9uvbXNVrVY"
   },
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b3384",
   "metadata": {
    "id": "VddxeYBEVrVZ"
   },
   "source": [
    "Let's start by importing required packages. **os** package is used to read files and directory structure, **numpy** is used to convert python list to numpy array and to perform required matrix operations and **matplotlib.pyplot** is used to plot the graph and display images in our training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8156d6",
   "metadata": {
    "id": "rtPGh2MAVrVa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c16ed",
   "metadata": {
    "id": "Jlchl4x2VrVg"
   },
   "source": [
    "### TODO: Import TensorFlow and Keras Layers\n",
    "\n",
    "In the cell below, import Tensorflow and the Keras layers and models you will use to build your CNN. Also, import the `ImageDataGenerator` from Keras so that you can perform image augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88179b5",
   "metadata": {
    "id": "KzKpWdemHbC_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e9c36",
   "metadata": {
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fee2c97",
   "metadata": {
    "id": "UZZI6lNkVrVm"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147873bc",
   "metadata": {
    "id": "DPHx8-t-VrVo"
   },
   "source": [
    "In order to build our image classifier, we can begin by downloading the flowers dataset. We first need to download the archive version of the dataset and after the download we are storing it to \"/tmp/\" directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4506a",
   "metadata": {
    "id": "_lPjfOmNVrVs"
   },
   "source": [
    "After downloading the dataset, we need to extract its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0b017",
   "metadata": {
    "id": "OYmOylPlVrVt"
   },
   "outputs": [],
   "source": [
    "_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "\n",
    "zip_file = tf.keras.utils.get_file(origin=_URL,\n",
    "                                   fname=\"flower_photos\",\n",
    "                                   extract=True)\n",
    "\n",
    "base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos/flower_photos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1232872",
   "metadata": {
    "id": "2yge5MKnnjMd"
   },
   "source": [
    "The dataset we downloaded contains images of 5 types of flowers:\n",
    "\n",
    "1. Rose\n",
    "2. Daisy\n",
    "3. Dandelion\n",
    "4. Sunflowers\n",
    "5. Tulips\n",
    "\n",
    "So, let's create the labels for these 5 classes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5cdad2",
   "metadata": {
    "id": "FiYVs1MEmNHf"
   },
   "outputs": [],
   "source": [
    "classes = ['roses', 'daisy', 'dandelion', 'sunflowers', 'tulips']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b9968",
   "metadata": {
    "id": "G1ymuCPS0_eu"
   },
   "source": [
    "Also, the dataset we have downloaded has following directory structure. n\n",
    "<pre style=\"font-size: 10.0pt; font-family: Arial; line-height: 2; letter-spacing: 1.0pt;\" >\n",
    "<b>flower_photos</b>\n",
    "|__ <b>daisy</b>\n",
    "|__ <b>dandelion</b>\n",
    "|__ <b>roses</b>\n",
    "|__ <b>sunflowers</b>\n",
    "|__ <b>tulips</b>\n",
    "</pre>\n",
    "\n",
    "As you can see there are no folders containing training and validation data. Therefore, we will have to create our own training and validation set. Let's write some code that will do this.\n",
    "\n",
    "\n",
    "The code below creates a `train` and a `val` folder each containing 5 folders (one for each type of flower). It then moves the images from the original folders to these new folders such that 80% of the images go to the training set and 20% of the images go into the validation set. In the end our directory will have the following structure:\n",
    "\n",
    "\n",
    "<pre style=\"font-size: 10.0pt; font-family: Arial; line-height: 2; letter-spacing: 1.0pt;\" >\n",
    "<b>flower_photos</b>\n",
    "|__ <b>daisy</b>\n",
    "|__ <b>dandelion</b>\n",
    "|__ <b>roses</b>\n",
    "|__ <b>sunflowers</b>\n",
    "|__ <b>tulips</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>daisy</b>: [1.jpg, 2.jpg, 3.jpg ....]\n",
    "    |______ <b>dandelion</b>: [1.jpg, 2.jpg, 3.jpg ....]\n",
    "    |______ <b>roses</b>: [1.jpg, 2.jpg, 3.jpg ....]\n",
    "    |______ <b>sunflowers</b>: [1.jpg, 2.jpg, 3.jpg ....]\n",
    "    |______ <b>tulips</b>: [1.jpg, 2.jpg, 3.jpg ....]\n",
    " |__ <b>val</b>\n",
    "    |______ <b>daisy</b>: [507.jpg, 508.jpg, 509.jpg ....]\n",
    "    |______ <b>dandelion</b>: [719.jpg, 720.jpg, 721.jpg ....]\n",
    "    |______ <b>roses</b>: [514.jpg, 515.jpg, 516.jpg ....]\n",
    "    |______ <b>sunflowers</b>: [560.jpg, 561.jpg, 562.jpg .....]\n",
    "    |______ <b>tulips</b>: [640.jpg, 641.jpg, 642.jpg ....]\n",
    "</pre>\n",
    "\n",
    "Since we don't delete the original folders, they will still be in our `flower_photos` directory, but they will be empty. The code below also prints the total number of flower images we have for each type of flower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e9efb",
   "metadata": {
    "id": "a-AL030LmcdD"
   },
   "outputs": [],
   "source": [
    "for cl in classes:\n",
    "  img_path = os.path.join(base_dir, cl)\n",
    "  images = glob.glob(img_path + '/*.jpg')\n",
    "  print(\"{}: {} Images\".format(cl, len(images)))\n",
    "  num_train = int(round(len(images)*0.8))\n",
    "  train, val = images[:num_train], images[num_train:]\n",
    "\n",
    "  for t in train:\n",
    "    if not os.path.exists(os.path.join(base_dir, 'train', cl)):\n",
    "      os.makedirs(os.path.join(base_dir, 'train', cl))\n",
    "    shutil.move(t, os.path.join(base_dir, 'train', cl))\n",
    "\n",
    "  for v in val:\n",
    "    if not os.path.exists(os.path.join(base_dir, 'val', cl)):\n",
    "      os.makedirs(os.path.join(base_dir, 'val', cl))\n",
    "    shutil.move(v, os.path.join(base_dir, 'val', cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b4997",
   "metadata": {
    "id": "yP85YhYol8ER"
   },
   "outputs": [],
   "source": [
    "round(len(images)*0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc516454",
   "metadata": {
    "id": "8Lp-0ejxOtP1"
   },
   "source": [
    "For convenience, let us set up the path for the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b242b98",
   "metadata": {
    "id": "uh68rmWspp0U"
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
